1
point
1. Question 1
If X is the standard notation for the input to an RNN, what are the standard notations for the outputs?


Y


H


- Y(hat) and H


H(hat) and Y

Question 21
point
2. Question 2
What is a sequence to vector if an RNN has 30 cells numbered 0 to 29


The Y(hat) for the first cell


The total Y(hat) for all cells


The average Y(hat) for all 30 cells


- The Y(hat) for the last cell

Question 31
point
3. Question 3
What does a Lambda layer in a neural network do?


Changes the shape of the input or output data


There are no Lambda layers in a neural network


- Allows you to execute arbitrary code while training


Pauses training without a callback

Question 41
point
4. Question 4
What does the axis parameter of tf.expand_dims do?


Defines the dimension index to remove when you expand the tensor


Defines the axis around which to expand the dimensions


Defines if the tensor is X or Y


- Defines the dimension index at which you will expand the shape of the tensor

Question 51
point
5. Question 5
A new loss function was introduced in this module, named after a famous statistician. What is it called?


Hubble loss


- Huber loss


Hawking loss


Hyatt loss

Question 61
point
6. Question 6
What’s the primary difference between a simple RNN and an LSTM


- In addition to the H output, LSTMs have a cell state that runs across all cells


In addition to the H output, RNNs have a cell state that runs across all cells


LSTMs have multiple outputs, RNNs have a single one


LSTMs have a single output, RNNs have multiple

Question 71
point
7. Question 7
If you want to clear out all temporary variables that tensorflow might have from previous sessions, what code do you run?


tf.cache.clear_session()


tf.cache.backend.clear_session()


- tf.keras.backend.clear_session() 


tf.keras.clear_session

Question 81
point
8. Question 8
What happens if you define a neural network with these two layers?

tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),

tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),

tf.keras.layers.Dense(1),


Your model will fail because you need return_sequences=True after each LSTM layer


Your model will compile and run correctly


- Your model will fail because you need return_sequences=True after the first LSTM layer


Your model will fail because you have the same number of cells in each LSTM

